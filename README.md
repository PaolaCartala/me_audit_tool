# EM Audit Tool - Azure Functions

## ğŸ“‹ Overview

The EM Audit Tool is an Azure Functions-based solution that automates the auditing and enhancement of medical progress notes for E/M (Evaluation and Management) coding compliance per AMA 2025 guidelines. The system uses AI agents to analyze medical documentation, assign appropriate E/M codes, and provide comprehensive auditing with confidence scoring.

## ğŸ—ï¸ Architecture

### Core Components

- **Enhancement Agent**: Analyzes medical progress notes and assigns appropriate E/M codes (99212-99215)
- **Auditor Agent**: Reviews enhancement recommendations for compliance and provides final audit results with confidence scoring
- **Orchestrator**: Coordinates the processing workflow using Azure Durable Functions
- **Export Functions**: Generate Excel and JSON reports

### Technology Stack

- **Azure Functions** (Python 3.10)
- **Azure Durable Functions** for workflow orchestration
- **Azure OpenAI** for AI-powered medical coding analysis
- **PydanticAI** for structured AI interactions
- **Pydantic** for data validation and serialization

## ğŸš€ Features

### âœ… Enhanced Auditing with Advanced Confidence System

- **Confidence Assessment Object**: Comprehensive confidence evaluation with score, tier, reasoning, and deductions
- **Score**: 0-100 integer scale indicating auditor certainty
- **Tier**: UI-friendly labels (Very High, High, Moderate, Low, Very Low)
- **Reasoning**: Bulleted explanation of factors that increase/decrease confidence
- **Score Deductions**: Specific point reductions with explanations (when score < 100)
- **Compliance Flags**: Automatic detection of documentation gaps and risks
- **Billing-Ready Notes**: Enhanced notes optimized for submission

### âœ… Comprehensive E/M Code Analysis

- Support for codes 99212, 99213, 99214, and 99215
- Detailed justifications based on AMA 2025 guidelines
- Recommendations for documentation enhancement
- Code evaluation and compliance assessment

### âœ… Flexible Deployment Options

- Azure Functions deployment
- Local development and testing
- Containerized deployment support
- CI/CD pipeline integration

## ğŸ“¦ Installation & Setup

### Prerequisites

- Python 3.10+
- Azure Functions Core Tools v4
- Azure CLI
- Azure OpenAI service deployment

### Environment Setup

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd em_audit_tool
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Linux/macOS
   # or
   .venv\Scripts\activate     # Windows
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**:
   ```bash
   cp local.settings.json.example local.settings.json
   # Edit local.settings.json with your Azure OpenAI credentials
   ```

### Required Environment Variables

```json
{
  "IsEncrypted": false,
  "Values": {
    "FUNCTIONS_WORKER_RUNTIME": "python",
    "AzureWebJobsFeatureFlags": "EnableWorkerIndexing",
    "AzureWebJobsStorage": "UseDevelopmentStorage=true",
    "AZURE_OPENAI_ENDPOINT": "https://your-instance.openai.azure.com/",
    "AZURE_OPENAI_KEY": "your-api-key",
    "AZURE_OPENAI_DEPLOYMENT_NAME": "your-deployment-name",
    "AZURE_OPENAI_API_VERSION": "2024-02-15-preview"
  }
}
```

## ğŸ’» Local Development

### Running Locally

1. **Start Azure Functions**:
   ```bash
   func start
   ```

2. **Test endpoints**:
   - Health check: `http://localhost:7071/api/health`
   - Start orchestration: `http://localhost:7071/api/orchestrations/from-samples`

### Quick Testing

Run the enhanced test script:
```bash
python test_quick.py
```

This script now includes confidence score testing and validation.

## ğŸš€ Deployment

## Environment-Based Deployment

This project includes automated deployment scripts for different environments using Make and Bash.

### Environment Configuration

The project supports two environments:

- **Development Environment** (`.env.development`)
- **Production Environment** (`.env.production`)

### Deployment Commands

#### Quick Deployment

Deploy to **Development**:
```bash
make dev
```

Deploy to **Production**:
```bash
make prod
```

#### Manual Environment Setup

Set up development environment:
```bash
make setup-dev
# or
./setup-env.sh dev
```

Set up production environment:
```bash
make setup-prod
# or
./setup-env.sh prod
```

#### Available Make Commands

```bash
make help        # Show all available commands
make dev         # Deploy to development (audit-tool-dev)
make prod        # Deploy to production (audit-tool)
make setup-dev   # Setup dev environment only (no deploy)
make setup-prod  # Setup prod environment only (no deploy)
```

### Deployment Process

Each deployment command automatically:

1. **Checks Azure Login**: Verifies if you're logged into Azure CLI (runs `az login` if needed)
2. **Environment Setup**: Copies the appropriate `.env` file (development or production)
3. **Function App Restart**: Restarts the target Azure Function App
4. **Code Deployment**: Publishes the latest code using Azure Functions Core Tools

### Prerequisites for Deployment

- Azure CLI installed and configured
- Azure Functions Core Tools v4
- Proper permissions for the target resource group (`AppliedAI`)
- Access to both function apps (`audit-tool` and `audit-tool-dev`)

## ï¿½ğŸ“Š API Endpoints

### Health Check
```http
GET /api/health
```

### Start Processing
```http
POST /api/orchestrations/from-samples?limit=2
```

### Download Reports
```http
GET /api/reports/excel/{instance_id}
GET /api/reports/json/{instance_id}
```

## ğŸ§ª Testing

### Testing Guide
See [Testing Guide](guide_testing_azure_functions.md) for detailed testing instructions.

### Expected Response Structure

```json
{
  "auditor_agent": {
    "final_assigned_code": "99214",
    "final_justification": "...",
    "confidence": {
      "score": 85,
      "tier": "High",
      "reasoning": "FACTORS INCREASING CONFIDENCE:\n- Comprehensive documentation of chronic conditions\n- Clear medical decision making elements\n\nFACTORS DECREASING CONFIDENCE:\n- External data review not explicitly documented",
      "score_deductions": [
        "- Score reduced by 10 points: External data review not explicitly documented",
        "- Score reduced by 5 points: Some laboratory values not detailed"
      ]
    },
    "audit_flags": [],
    "billing_ready_note": "...",
    "code_evaluations": {
      "code_99212_evaluation": "...",
      "code_99213_evaluation": "...",
      "code_99214_evaluation": "...",
      "code_99215_evaluation": "..."
    }
  }
}
```

### Confidence Assessment System

#### Confidence Tiers & Score Ranges
- **90-100 (Very High)**: Clear, unambiguous documentation fully supports the assigned code
- **70-89 (High)**: Good documentation supports the code with minor gaps or ambiguities
- **50-69 (Moderate)**: Reasonable support for the code but some uncertainties or missing elements
- **30-49 (Low)**: Limited support, significant gaps, or borderline between codes
- **0-29 (Very Low)**: Poor documentation, major gaps, or conflicting evidence

#### Enhanced Features
- **Structured Reasoning**: Organized bullets showing confidence factors
- **Explicit Deductions**: Point-by-point score reductions with explanations
- **UI-Ready Labels**: Tier labels for frontend integration
- **Workflow Integration**: Confidence thresholds for auto-approval and review routing

For complete confidence system documentation, see [CONFIDENCE_TIERS.md](CONFIDENCE_TIERS.md).

## ğŸ“ Project Structure

```
em_audit_tool/
â”œâ”€â”€ __init__.py                     # Package initialization
â”œâ”€â”€ constants.py                    # Application constants
â”œâ”€â”€ function_app.py                 # Main Azure Functions app configuration
â”œâ”€â”€ host.json                       # Azure Functions host configuration
â”œâ”€â”€ settings.py                     # Application settings and logger config
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ local.settings.json             # Local development settings
â”œâ”€â”€ LICENSE                         # Project license
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ Makefile                        # Deployment automation
â”œâ”€â”€ setup-env.sh                    # Environment setup script
â”œâ”€â”€ .env.development                # Development environment variables
â”œâ”€â”€ .env.production                 # Production environment variables
â”œâ”€â”€ agents/                         # AI agent implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ em_auditor_agent.py         # Core auditor agent
â”‚   â”œâ”€â”€ em_enhancement_agent.py     # Enhancement agent
â”‚   â”œâ”€â”€ em_progress_note_agent.py   # Progress note agent
â”‚   â”œâ”€â”€ optimized_em_auditor_agent.py    # Optimized auditor version
â”‚   â”œâ”€â”€ optimized_em_enhancement_agent.py # Optimized enhancement version
â”‚   â”œâ”€â”€ models/                     # Agent data models
â”‚   â””â”€â”€ prompts/                    # Agent prompt templates
â”œâ”€â”€ data/                           # Sample data and test files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pdf_processor.py            # PDF processing utilities
â”‚   â”œâ”€â”€ patient_intake.json         # Sample patient data
â”‚   â”œâ”€â”€ checkoutsheet_*.json        # Sample checkout sheets
â”‚   â”œâ”€â”€ dictation_success_*.json    # Sample dictation data
â”‚   â”œâ”€â”€ 35_test/                    # Test dataset (35 samples)
â”‚   â”œâ”€â”€ 500_data/                   # Large test dataset (500 samples)
â”‚   â”œâ”€â”€ 500_run_0707/              # Test run results
â”‚   â”œâ”€â”€ completed/                  # Processed samples
â”‚   â””â”€â”€ samples/                    # Sample input files
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ CONFIDENCE_TIERS.md         # Confidence scoring documentation
â”‚   â”œâ”€â”€ guide_testing_azure_functions.md # Testing guide
â”‚   â””â”€â”€ user_feedback_system.md     # User feedback system docs
â”œâ”€â”€ durable_functions/              # Azure Durable Functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ auditor_agent_activity/     # Auditor agent activity function
â”‚   â”œâ”€â”€ download_json_report/       # JSON report download function
â”‚   â”œâ”€â”€ download_report/            # Excel report download function
â”‚   â”œâ”€â”€ em_coding_orchestrator/     # Main orchestrator function
â”‚   â”œâ”€â”€ em_progress_note_orchestrator/ # Progress note orchestrator
â”‚   â”œâ”€â”€ enhancement_agent_activity/ # Enhancement agent activity
â”‚   â”œâ”€â”€ excel_export_activity/      # Excel export activity
â”‚   â”œâ”€â”€ get_feedback_analytics/     # Feedback analytics function
â”‚   â”œâ”€â”€ health/                     # Health check function
â”‚   â”œâ”€â”€ progress_note_agent_activity/ # Progress note agent activity
â”‚   â”œâ”€â”€ start_orchestration_from_body/ # Start orchestration from request body
â”‚   â”œâ”€â”€ start_orchestration_from_samples/ # Start orchestration from samples
â”‚   â”œâ”€â”€ progress_note_from_id/      # Start progress note processing
â”‚   â””â”€â”€ submit_feedback/            # User feedback submission
â”œâ”€â”€ guidelines/                     # Medical coding guidelines
â”‚   â”œâ”€â”€ ama_em_guideline.pdf        # AMA E/M guidelines (PDF)
â”‚   â””â”€â”€ em_guideline.md             # E/M guidelines (Markdown)
â”œâ”€â”€ run_tests/                      # Test execution and results
â”‚   â”œâ”€â”€ 500_run.zip                 # Archived test runs
â”‚   â”œâ”€â”€ combined_results_*.xlsx     # Combined test results
â”‚   â”œâ”€â”€ test_results_*.json         # JSON test results
â”‚   â””â”€â”€ 500_run/                    # Individual test run data
â”œâ”€â”€ services/                       # Business logic services
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ feedback_service.py         # User feedback service
â”œâ”€â”€ test/                           # Test scripts and utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ diagnose_mcp.py             # MCP diagnostic tools
â”‚   â”œâ”€â”€ get_headers.py              # HTTP header testing
â”‚   â”œâ”€â”€ json_to_excel_converter.py  # Data conversion utilities
â”‚   â”œâ”€â”€ test_agent.py               # Agent testing
â”‚   â”œâ”€â”€ test_enhacement_new.py      # Enhancement testing
â”‚   â”œâ”€â”€ test_feedback_endpoints.py  # Feedback API testing
â”‚   â”œâ”€â”€ test_latency.py             # Performance testing
â”‚   â”œâ”€â”€ test_optimized_agents.py    # Optimized agent testing
â”‚   â””â”€â”€ test_quick.py               # Quick testing script
â”œâ”€â”€ test_results/                   # Test output and results
â”‚   â”œâ”€â”€ gpt5_result*.json           # GPT-5 test results
â”‚   â”œâ”€â”€ new_confidence.json         # Confidence system results
â”‚   â”œâ”€â”€ new_reasoning_*.json        # Reasoning test results
â”‚   â”œâ”€â”€ optimized_prompts.json      # Prompt optimization results
â”‚   â””â”€â”€ result_*.json               # Various test results
â””â”€â”€ utils/                          # Utility functions and helpers
    â””â”€â”€ ...                         # Utility modules
```

## ğŸ”§ Configuration

### Host Configuration (host.json)
```json
{
  "version": "2.0",
  "logging": {
    "logLevel": {
      "default": "Information"
    }
  },
  "functionTimeout": "00:10:00",
  "extensions": {
    "durableTask": {
      "hubName": "EMCodingHub",
      "storageProvider": {
        "maxQueuePollingInterval": "00:00:02"
      }
    }
  }
}
```

### Function App Configuration (function_app.py)
The main function app includes:
- HTTP triggers for API endpoints
- Durable function orchestrators
- Activity functions for processing
- Timer triggers for scheduled tasks

## ğŸ” Troubleshooting

### Common Issues

1. **Azure OpenAI Connection Issues**:
   - Verify endpoint URL and API key
   - Check deployment name and API version
   - Ensure proper network connectivity

2. **Function Timeout**:
   - Increase `functionTimeout` in host.json
   - Optimize processing for large documents
   - Consider breaking down large batches

3. **Memory Issues**:
   - Monitor memory usage with large document sets
   - Implement document size limits
   - Use streaming for large files

### Debug Mode

Enable detailed logging by setting:
```json
{
  "logging": {
    "logLevel": {
      "default": "Debug"
    }
  }
}
```

## ğŸ“ˆ Performance

### Processing Time Estimates
- **2 documents**: 2-5 minutes
- **5 documents**: 5-10 minutes  
- **10 documents**: 10-15 minutes

### Optimization Tips
- Use embedded guidelines for better performance
- Implement caching for repeated requests
- Monitor Azure OpenAI usage and quotas
- Scale Azure Functions based on workload

## ğŸ”’ Security

### Best Practices
- Store API keys in Azure Key Vault
- Use managed identities when possible
- Implement proper access controls
- Monitor and audit API usage
- Encrypt sensitive data at rest and in transit

## ğŸ“‹ License

[License information]

## ğŸ¤ Contributing

[Contributing guidelines]

## ğŸ“ Support

[Support contact information]

---

**Last Updated**: August 2025  
**Version**: 2.0.0  
**Features**: Enhanced with Confidence Scoring and Comprehensive Auditing
